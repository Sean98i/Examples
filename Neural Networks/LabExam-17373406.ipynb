{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have either given, sought, nor received aid during this examination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the j'th position\n",
    "    and zeroes elsewhere.  This is used to convert a digit (0...9)\n",
    "    into a corresponding desired output from the neural network.\n",
    "\n",
    "    \"\"\"\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename): # loads the weights and biases from a previosuly saved network\n",
    "    \"\"\"Load a neural network from the file ``filename``.  Returns an\n",
    "    instance of Network.\n",
    "\n",
    "    \"\"\"\n",
    "    f = open(filename, \"r\")\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    cost = getattr(sys.modules[__name__], data[\"cost\"])\n",
    "    net = Network(data[\"sizes\"], cost=cost)\n",
    "    net.weights = [np.array(w) for w in data[\"weights\"]]\n",
    "    net.biases = [np.array(b) for b in data[\"biases\"]]\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def tanh(z):\n",
    "    return (1+np.tanh(z/2))/2\n",
    "\n",
    "def tanh_prime(z):\n",
    "    return (1/(np.cosh(z/2)**2))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticCost(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def fn(a, y):\n",
    "        \"\"\"Return the cost associated with an output ``a`` and desired output\n",
    "        ``y``.\n",
    "\n",
    "        \"\"\"\n",
    "        return 0.5*np.linalg.norm(a-y)**2\n",
    "\n",
    "    @staticmethod\n",
    "    def delta(z, a, y):\n",
    "        \"\"\"Return the error delta from the output layer.\"\"\"\n",
    "        return (a-y) * tanh_prime(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyCost(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def fn(a, y):\n",
    "        \"\"\"Return the cost associated with an output ``a`` and desired output\n",
    "        ``y``.  Note that np.nan_to_num is used to ensure numerical\n",
    "        stability.  In particular, if both ``a`` and ``y`` have a 1.0\n",
    "        in the same slot, then the expression (1-y)*np.log(1-a)\n",
    "        returns nan.  The np.nan_to_num ensures that that is converted\n",
    "        to the correct value (0.0).\n",
    "\n",
    "        \"\"\"\n",
    "        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
    "\n",
    "    @staticmethod\n",
    "    def delta(z, a, y):\n",
    "        \"\"\"Return the error delta from the output layer.  Note that the\n",
    "        parameter ``z`` is not used by the method.  It is included in\n",
    "        the method's parameters in order to make the interface\n",
    "        consistent with the delta method for other cost classes.\n",
    "\n",
    "        \"\"\"\n",
    "        return (a-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes, cost=QuadraticCost): # need to tell the network what cost function to use\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the respective\n",
    "        layers of the network.  For example, if the list was [2, 3, 1]\n",
    "        then it would be a three-layer network, with the first layer\n",
    "        containing 2 neurons, the second layer 3 neurons, and the\n",
    "        third layer 1 neuron.  The biases and weights for the network\n",
    "        are initialized randomly, using\n",
    "        ``self.default_weight_initializer`` (see docstring for that\n",
    "        method).\n",
    "\n",
    "        \"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.default_weight_initializer() # intialsises the weights\n",
    "        self.cost=cost\n",
    "\n",
    "    def default_weight_initializer(self):\n",
    "        \"\"\"Initialize each weight using a Gaussian distribution with mean 0\n",
    "        and standard deviation 1 over the square root of the number of\n",
    "        weights connecting to the same neuron.  Initialize the biases\n",
    "        using a Gaussian distribution with mean 0 and standard\n",
    "        deviation 1.\n",
    "\n",
    "        Note that the first layer is assumed to be an input layer, and\n",
    "        by convention we won't set any biases for those neurons, since\n",
    "        biases are only ever used in computing the outputs from later\n",
    "        layers.\n",
    "\n",
    "        \"\"\"\n",
    "        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)/np.sqrt(x)\n",
    "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "\n",
    "    def large_weight_initializer(self):\n",
    "        \"\"\"Initialize the weights using a Gaussian distribution with mean 0\n",
    "        and standard deviation 1.  Initialize the biases using a\n",
    "        Gaussian distribution with mean 0 and standard deviation 1.\n",
    "\n",
    "        Note that the first layer is assumed to be an input layer, and\n",
    "        by convention we won't set any biases for those neurons, since\n",
    "        biases are only ever used in computing the outputs from later\n",
    "        layers.\n",
    "\n",
    "        This weight and bias initializer uses the same approach as in\n",
    "        Chapter 1, and is included for purposes of comparison.  It\n",
    "        will usually be better to use the default weight initializer\n",
    "        instead.\n",
    "\n",
    "        \"\"\"\n",
    "        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = tanh(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, # eta is the learning rate\n",
    "            lmbda = 0.0,\n",
    "            evaluation_data=None,\n",
    "            monitor_evaluation_cost=False,\n",
    "            monitor_evaluation_accuracy=False,\n",
    "            monitor_training_cost=False,\n",
    "            monitor_training_accuracy=False,\n",
    "            early_stopping_n = 0):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic gradient\n",
    "        descent.  The ``training_data`` is a list of tuples ``(x, y)``\n",
    "        representing the training inputs and the desired outputs.  The\n",
    "        other non-optional parameters are self-explanatory, as is the\n",
    "        regularization parameter ``lmbda``.  The method also accepts\n",
    "        ``evaluation_data``, usually either the validation or test\n",
    "        data.  We can monitor the cost and accuracy on either the\n",
    "        evaluation data or the training data, by setting the\n",
    "        appropriate flags.  The method returns a tuple containing four\n",
    "        lists: the (per-epoch) costs on the evaluation data, the\n",
    "        accuracies on the evaluation data, the costs on the training\n",
    "        data, and the accuracies on the training data.  All values are\n",
    "        evaluated at the end of each training epoch.  So, for example,\n",
    "        if we train for 30 epochs, then the first element of the tuple\n",
    "        will be a 30-element list containing the cost on the\n",
    "        evaluation data at the end of each epoch. Note that the lists\n",
    "        are empty if the corresponding flag is not set.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # early stopping functionality:\n",
    "        best_accuracy=1\n",
    "\n",
    "        training_data = list(training_data)\n",
    "        n = len(training_data)\n",
    "\n",
    "        if evaluation_data:\n",
    "            evaluation_data = list(evaluation_data)\n",
    "            n_data = len(evaluation_data)\n",
    "\n",
    "        # early stopping functionality:\n",
    "        best_accuracy=0\n",
    "        no_accuracy_change=0\n",
    "\n",
    "        evaluation_cost, evaluation_accuracy = [], []\n",
    "        training_cost, training_accuracy = [], []\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(\n",
    "                    mini_batch, eta, lmbda, len(training_data))\n",
    "\n",
    "            print(\"Epoch %s training complete\" % j)\n",
    "\n",
    "            if monitor_training_cost:\n",
    "                cost = self.total_cost(training_data, lmbda)\n",
    "                training_cost.append(cost)\n",
    "                print(\"Cost on training data: {}\".format(cost))\n",
    "            if monitor_training_accuracy:\n",
    "                accuracy = self.accuracy(training_data, convert=True)\n",
    "                training_accuracy.append(accuracy)\n",
    "                print(\"Accuracy on training data: {} / {}\".format(accuracy, n))\n",
    "            if monitor_evaluation_cost:\n",
    "                cost = self.total_cost(evaluation_data, lmbda, convert=True)\n",
    "                evaluation_cost.append(cost)\n",
    "                print(\"Cost on evaluation data: {}\".format(cost))\n",
    "            if monitor_evaluation_accuracy:\n",
    "                accuracy = self.accuracy(evaluation_data)\n",
    "                evaluation_accuracy.append(accuracy)\n",
    "                print(\"Accuracy on evaluation data: {} / {}\".format(self.accuracy(evaluation_data), n_data))\n",
    "\n",
    "            # Early stopping:\n",
    "            if early_stopping_n > 0:\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    no_accuracy_change = 0\n",
    "                    #print(\"Early-stopping: Best so far {}\".format(best_accuracy))\n",
    "                else:\n",
    "                    no_accuracy_change += 1\n",
    "\n",
    "                if (no_accuracy_change == early_stopping_n):\n",
    "                    #print(\"Early-stopping: No accuracy change in last epochs: {}\".format(early_stopping_n))\n",
    "                    return evaluation_cost, evaluation_accuracy, training_cost, training_accuracy\n",
    "\n",
    "        return evaluation_cost, evaluation_accuracy, \\\n",
    "            training_cost, training_accuracy\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta, lmbda, n):\n",
    "        \"\"\"Update the network's weights and biases by applying gradient\n",
    "        descent using backpropagation to a single mini batch.  The\n",
    "        ``mini_batch`` is a list of tuples ``(x, y)``, ``eta`` is the\n",
    "        learning rate, ``lmbda`` is the regularization parameter, and\n",
    "        ``n`` is the total size of the training data set.\n",
    "\n",
    "        \"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = tanh(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = (self.cost).delta(zs[-1], activations[-1], y)\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = tanh_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def accuracy(self, data, convert=False):\n",
    "        \"\"\"Return the number of inputs in ``data`` for which the neural\n",
    "        network outputs the correct result. The neural network's\n",
    "        output is assumed to be the index of whichever neuron in the\n",
    "        final layer has the highest activation.\n",
    "\n",
    "        The flag ``convert`` should be set to False if the data set is\n",
    "        validation or test data (the usual case), and to True if the\n",
    "        data set is the training data. The need for this flag arises\n",
    "        due to differences in the way the results ``y`` are\n",
    "        represented in the different data sets.  In particular, it\n",
    "        flags whether we need to convert between the different\n",
    "        representations.  It may seem strange to use different\n",
    "        representations for the different data sets.  Why not use the\n",
    "        same representation for all three data sets?  It's done for\n",
    "        efficiency reasons -- the program usually evaluates the cost\n",
    "        on the training data and the accuracy on other data sets.\n",
    "        These are different types of computations, and using different\n",
    "        representations speeds things up.  More details on the\n",
    "        representations can be found in\n",
    "        mnist_loader.load_data_wrapper.\n",
    "\n",
    "        \"\"\"\n",
    "        if convert:\n",
    "            results = [(np.argmax(self.feedforward(x)), np.argmax(y))\n",
    "                       for (x, y) in data]\n",
    "        else:\n",
    "            results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in data]\n",
    "\n",
    "        result_accuracy = sum(int(x == y) for (x, y) in results)\n",
    "        return result_accuracy\n",
    "\n",
    "    def total_cost(self, data, lmbda, convert=False):\n",
    "        \"\"\"Return the total cost for the data set ``data``.  The flag\n",
    "        ``convert`` should be set to False if the data set is the\n",
    "        training data (the usual case), and to True if the data set is\n",
    "        the validation or test data.  See comments on the similar (but\n",
    "        reversed) convention for the ``accuracy`` method, above.\n",
    "        \"\"\"\n",
    "        cost = 0.0\n",
    "        for x, y in data:\n",
    "            a = self.feedforward(x)\n",
    "            if convert: y = vectorized_result(y)\n",
    "            cost += self.cost.fn(a, y)/len(data)\n",
    "            cost += 0.5*(lmbda/len(data))*sum(np.linalg.norm(w)**2 for w in self.weights) # '**' - to the power of.\n",
    "        return cost\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"Save the neural network to the file ``filename``.\"\"\"\n",
    "        data = {\"sizes\": self.sizes,\n",
    "                \"weights\": [w.tolist() for w in self.weights],\n",
    "                \"biases\": [b.tolist() for b in self.biases],\n",
    "                \"cost\": str(self.cost.__name__)}\n",
    "        f = open(filename, \"w\")\n",
    "        json.dump(data, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9239 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9445 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9540 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9569 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9621 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9598 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9643 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9659 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [9239, 9445, 9540, 9569, 9621, 9598, 9643, 9659], [], [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network([784, 40, 20, 10], cost=QuadraticCost)\n",
    "net.default_weight_initializer()\n",
    "net.SGD(training_data, 8, 20, 1.8, evaluation_data=test_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9048 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9204 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9285 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9340 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9382 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9445 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [9048, 9204, 9285, 9340, 9382, 9445], [], [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network([784, 60, 10], cost=CrossEntropyCost)\n",
    "net.default_weight_initializer()\n",
    "net.SGD(training_data, 6, 100, 0.3, evaluation_data=test_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9200 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9398 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9474 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9535 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9538 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [9200, 9398, 9474, 9535, 9467, 9467, 9538], [], [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network([784, 30, 25, 20, 10], cost=CrossEntropyCost)\n",
    "net.default_weight_initializer()\n",
    "net.SGD(training_data, 7, 10, 0.3, evaluation_data=test_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = np.array([0,1,2,3,4,5,6,7])\n",
    "xii = np.array([0,1,2,3,4,5])\n",
    "xiii = np.array([0,1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = np.array([9239, 9445, 9540, 9569, 9621, 9598, 9643, 9659])\n",
    "yii = np.array([9048, 9204, 9285, 9340, 9382, 9445])\n",
    "yiii = np.array([9200, 9398, 9474, 9535, 9467, 9467, 9538])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x241ec920940>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XlclVX+wPHPYV8FBVFEEFQUN0TFLbM9c5ssLUtbbLVFf9nMNJXptNkybZPtTalpm0uaaWqZ1rRoueCGoqK4siiLILJz4Z7fH8/V0QRBBZ7Lvd/36+VLOJx7n+8tPN/nOavSWiOEEML5uJgdgBBCCHNIAhBCCCclCUAIIZyUJAAhhHBSkgCEEMJJSQIQQggnJQlACCGclCQAIYRwUpIAhBDCSbmZHcC5BAcH68jISLPDEEKIRmXTpk05WuvmNdWz6wQQGRlJQkKC2WEIIUSjopQ6VJt60gUkhBBOShKAEEI4KUkAQgjhpCQBCCGEk5IEIIQQTkoSgBBCOClJAEII4aTseh2AEEI4A6tVk1NURnpeCRnHS0k/Xoyfpztj+0bU63UlAQghRD0rtVRyNL+U9OMlxp+8EjJsX2ccLyEjv5TyCusZr+kZESgJQAgh7JnWmvwSSxUNeylptgY+u6DsjNcoBSH+noQFetM1LIDrurYkLNCbsEBvWgV6E9bUmyZe7vUeuyQAIYQ4h4pKK5kFZWc07qc39hnHSygqrzzjNZ5uLkaD3tSbmI4hhDW1Ney2Py0DvPBwM38IVhKAEMKpFZVVkHG85NTd+p/v4o+eKKXSqs94TTNfD8ICvWnb3JeB0c1pFehFa1sj3yrQmyBfD5RSJn2i2pMEIIRweAWlFtamHCM1t/jMO/j8Eo4XW86o6+aiaBngRVigN32jmp1x937yb28PV5M+Sd2SBCCEcEgFpRZ+3JXF8u1H+GVP9qlBVj9Pt1PdMz3bBBIW6HPGHXyIvxeuLvZ/914XJAEIIRxGYVkFP+7KZHniEX62Nfotm3hxW98IhnQNpWNLfwK8639wtbGQBCCEaNSKyir4cXcWyxMz+Dk5m7IKKy2aeDK2TwTDY0PpGdEUFye5oz9fkgCEEI1OUVkFP+3OYnniEf6bnEVZhZUQf0/G9IlgWGwovaTRrxVJAEKIRqG4/MxGv9Ripbm/J7f2DmdYbCvi20ijf74kAQgh7FZxeQX/3Z3Niu1H+HF3JqUWK8F+noyOD2dot1B6RzZzmgHb+iAJQAg7obVmX3YRwX4eBPp4mB2OaUrKK/lvsjF756ddWZRYKgn28+DmXkaj3ydKGv26IglACJNlFZTy9eZ0FiSksj+7CDC2CejY0p/oEH86tvSjQwt/olv44+fpmP9kSy2V/JycxbLEI/xoa/SDfD0Y2TOMYbGh9I0Kkka/Hjjmb5MQdq6i0srPydnMT0jlp91ZVFo18W2acvcNUZSUV5B8tJA9mQV8ueEQpZb/bRLWuqk3HVr406HF/xJDu+Z+eLk3voVJRqOfzfLtR/hxVybF5ZU08/Xgxp5hDLfd6bu5mr9dgiOTBCBEAzqQU8SChFQWbUojq6CMYD8P7rs0ipvjw2kf4ndW/UqrJi2vmOSjBezJLCA5s5A9Rwv4bW82lkpjewIXBZFBvkZiaOlPR1tyaBPki7udNaCllkp+2ZPN8kSj0S8qr6Spjzsj4sIYHhtKX2n0G5QkACHqWUl5Jd/tOMK8jalsOJCLi4IrO4Ywunc4V8WEnLORdnVRtAnypU2QL4O6tDxVbqm0cjCniOTMAvYcLTD+zizgh51HObltjYerC22b+9qeFmxPDS38ad3Uu0Fny5RaKvl1z8k7/SwKyypo6uPO9XGtGNotlP5tg6TRN0mtEoBSahJwP6CAj7XW023l/wdMBCqA5Vrrx23lk4F7gUrgEa31Slv5YOAtwBWYobX+V91+HCHsg9aa7en5zN+YytKtGRSUVRAZ5MM/ruvITb1a06KJ10W9v7urC9G2cQFi/1deaqkkJavQ9rRQwN7MQjYdymPptoxTdbzdXYlu4XcqIZx8amjRxLPONjArq6jk1z05rNh+hFU7MyksqyDQx53hsaFGo98uyO6eTpxRjQlAKdUVo/HvA5QD3yullgOtgRFArNa6TCkVYqvfGbgV6AK0AlYrpTrY3u494FogDdiolFqqtd5Zx59JCNPkFZXzzdZ05m9MZffRArzcXRjaNZTRvcPpG9Ws3neI9HJ3pWtYAF3DAs4oLyi1sDer8NTTwt7MQn7Zk83CTWmn6vh7uZ2REIyxBj+C/Dxrde2yikp+O63RLyirIMDbnaHdWjIsthWXSKNvd2rzBNAJWKe1LgZQSv0C3AjEA//SWpcBaK2zbPVHAPNs5QeUUikYyQMgRWu93/Y+82x1JQGIRs1q1azdl8P8jan8kJRJeaWV2NYBvHBDV66Pa9UgB3vUxN/LnZ4RTekZ0fSM8tyicvbYuo/2ZBaw52ghy7Zl8GVpxak6wX4epw08G0khuoU/TbzcKa+wsiYlm2WJR1iVZDT6TbzcGNy1JcNiQxnQPlgafTtWmwSwA3hRKRUElABDgQSgAzBQKfUiUAo8prXeCIQB6057fZqtDCD1T+V9/3wxpdR4YDxARET9HocmxMVIP17CVwmpfJWQRvrxEgJ9jDNcb+kdTqfQJmaHVyvNfD3o1zaIfm2DTpVprckqKDs18Hxy8HlBQirFpx180irAi4KyCgpKK/D3cuO6k41+u2C7OOxE1KzGBKC13qWUegVYBRQC2zD6/N2ApkA/oDewQCnVFmOc4Ky3Aar6jdBnFWj9EfARQHx8/Fk/F8JMZRWVrNqZyfyNqaxJyQHg0vbBPDkkhms7t2iU0zH/TClFiyZetGjixWUdmp8qt1o16cdLjMSQVUDy0QI8XF0Y2s2405dGv/Gp1SCw1nomMBNAKfUSxt17J+BrrbUGNiilrECw7Wfhp728NXByBKq6ciHs2u6jJ5i/MZVvtqSTV2whLNCbR66K5ub41rRu6mN2eA3CxUUR3syH8GY+XNO5hdnhiDpQ21lAIVrrLKVUBDAS6A9YgauAn22DvB5ADrAU+FIp9W+MQeBoYAPGk0G0UioKSMcYKB5bx59HiDpTUGph6bYMFmxMZVtaPh6uLlzbpQW3xIczoH2wrEwVjV5t1wEsso0BWIAJWus8pdQsYJZSagfG7KBxtqeBJKXUAozB3Qpb/UoApdREYCXGNNBZWuukOv48QlwUrTUbDuQyPyGVFduPUGqxEtPSn6eHd+aGHmE083XePXqE41FGm22f4uPjdUJCgtlhCCeQdaKUhZvT+CohjQM5Rfh7uvGXuFbcEh9ObOuARnHAtxAnKaU2aa3ja6onK4GF06qotPLf5GzmbzzMf5OzqbRq+kQ1Y+KV7RnaLdRhDv4WojqSAITT2Z9dyIKENBZtTiO7oIzm/p6Mv6wto+PDiQr2NTs8IRqMJADhFIrLK1ix/SgLNqay4WAuri6KKzuGcEvvcK7s2Fz2ohFOSRKAcFj5xRa2ph3n+x1H+XZbBoVlFbQN9uWJwTGM6hlGyEXuxyNEYycJQDgES6WV3UcK2Jqax5bU42w9fJz9OcbhKt7urgztFsotvcPpHdlUBnSFsJEEIBodrY0VqVttDf3W1ONsT8+nrMI4OCXYz5O48EBG9WpNj/BAuocH4uugJ2kJcTHkX4Wwe4VlFSSmHjfu7G1/sgvKAPB0c6FrWAC392tDj4hA4sIDCQv0lrt8IWpBEoCwK5VWzZ7MgjPu7vdkFXByuUrbYF8Gtg8mLiKQHuFNiQn1l90mhbhAkgCEqbJOlLL58Mk7+zy2p+VTZNtxMtDHnbjwQIZ0a0lcuHF3H+gjK3GFqCuSAESDKSmvZEdGPlsPH2dLah5bDx8nI78UAHdXRafQJtzUqzVxEYHEhTclMshHunKEqEeSAES9sFo1+3OKTt3Zbzl8nN1HC6i0HVjbuqk3vSKbca/tzr5LqyYOsZWyEI2JJABRJ3KLytlqu6vfknqcbanHOWE7Vcrf043Y8AAeurwdcbZZOc39a3fMoBCi/kgCEOetrKKSnRknTs3I2Zp6nEPHigFwUdCxZROGxbaiR0QgPcIDadfcDxfZOlkIuyMJQNSa1pqvEtJ4ftlOCsuMu/uWTbyICw9kTJ8IeoQH0q11AD4e8msl7EtZZRmL9y7mhvY34OUmK8BPkn+polbyisqZ/PV2vk86St+oZtx1SSRxEYGEBnibHdo5JecmU2gppGdITxlQdkIV1gq+3fct7297n6NFR/H38GdY22Fmh2U3JAGIGv22N5vHvtpGblE5Tw6J4f6Bbe36NCytNWsz1jJ7x2zWH10PQGxwLBPiJtC/VX9JBE5Aa83qw6t5Z8s7HMg/QJegLjx/yfP0b9Xf7NDsiiQAUa1SSyWvrUxm5poDtA/xY+a43nQNCzA7rGqVV5az4sAK5iTNIeV4CiE+Ifyt19/wdfdlxvYZPLD6AeKaxzGhxwT6tuwricBB/ZHxB29tfoukY0m0DWjLm1e8ydURV8v/7yrIiWCiSruPnuDReVvZfbSAO/u3YfKQTnZ7QMqJ8hMsSF7Al7u+JLskm+im0dzV5S6GRA7B3dUdMJLD4r2L+Wj7R2QVZ9GrRS8mxE2gd8veJkcv6kpidiJvb36b9UfXE+obykPdH+Iv7f6Cm4vz3efW9kQwSQDiDFar5pPfD/LK97tp4uXGqzfFclVMC7PDqlJGYQaf7fyMr/d+TXFFMf1D+3NXl7vO2c1TVlnGoj2LmLF9Btkl2fRp2YeH4x6mV4teDRy9qCspeSm8s+Udfkr9iWZezbi/2/2M7jgaD1fnXTUuCUCct8wTpTz21TZ+25vDVTEhvHpTLMF+9jdfP+lYEnN2zOGHQz+gUAyOGsxdXe6iY7OOtX6P0opSFu5ZyIztMzhWeox+of2YEDeBuJC4eoxc1KX0wnTe3/o+y/Yvw9vNm3FdxnFn5zvxdZdT3SQBiPPy/Y6jTP46kRJLJVOGdeb2vhF21Wdq1VbWpK9hTtIcNhzdgK+7Lzd3uJnbOt1GS9+WF/y+JRUlLEhewKwds8gtzWVAqwE8HPcwsc1j6zB6UZdySnL4OPFjFuxZgAsujIkZw73d7qWpV1OzQ7MbkgBErRSVVfD8tzuZn5BK17AmTL+lB+1D/MwO65TyynKW71/OnKQ57MvfRwufFtzR+Q5GRo/E38O/zq5TbClmfvJ8PtnxCXlleQwMG8iEuAl0Ce5SZ9cQF6egvIDZSbP5bOdnlFeWc0P7G3iw+4MXdQPgqCQBiBptTT3Oo/O2cCi3mAcvb8dfr+mAh5t9bK2cX5bPV3u+4otdX5BTkkPHph0Z12Ucg6MG4+7iXm/XLbYU8+XuL5mdNJv8snyuaH0FD8c9TKegTvV2TXFupRWlzN09l5k7ZpJfls91kdcxMW4ikQGRZodmt+o0ASilJgH3Awr4WGs9XSn1rK0s21btKa31Clv9ycC9QCXwiNZ6pa18MPAW4ArM0Fr/61zXlQRQPyoqrbz/8z7e+nEvLfw9+fctcfRrG2R2WACkFaTx+a7P+Xrv15RUlDCg1QDGdRlHv9B+DdolVVheeCoRFJQXcFX4VTwc9/B5jTOIi2OxWvgm5Rs+3PYhWcVZDGg1gEd6PkLnoM5mh2b36iwBKKW6AvOAPkA58D3wEHAbUKi1fv1P9TsDc231WwGrgQ62H+8BrgXSgI3AGK31zuquLQmg7qXmFvPo/K1sOpTH9d1bMe2GrgR4198ddW0l5STxSdInrDq0ChdcGNp2KHd2vtP0BregvIDPd33OZ0mfUWAp4No21/JQ94eIbhptalyOzKqtrDy4kne3vMvhgsN0b96dST0nyZTd81DbBFCbCbKdgHVa62LbG/8C3HiO+iOAeVrrMuCAUioFIxkApGit99veZ56tbrUJQNQdrTVfb07nmaVJKGD6LXHc0CPM1Jis2spvab8xO2k2CZkJ+Ln7Ma7LOMbGjLWbfl1/D38e6v4QY2PG8tnOz/h81+esPrSaQZGDeKj7Q7QLbGd2iA5Da82a9DW8veVtdufupn1ge96+8m2uCL/CriYkOJLaJIAdwItKqSCgBBgKJADHgIlKqTtt3/9da50HhAHrTnt9mq0MIPVP5X0vLnxRG/nFFp76ZjvLE4/QJ7IZb4zuTngzH9PiKassOzWwuz9/Py19W/JY/GOMih6Fn4f9DECfLsAzgIk9JnJH5zuYkzSHL3Z9wQ8Hf2Bw1GAe7P4gbQPamh1io7YlawvTN01nc9ZmwvzCeOnSlxgaNRRXF/tcfOgoakwAWutdSqlXgFVAIbANqAA+AKYB2vb3G8A9GOMEZ70NUNXo4ln9T0qp8cB4gIiIiFp9CFG93/fl8PcF28guKOMf13XkwcvbmbaPT35ZPvOT5/Plri85VnqMmGYx/GvgvxgUOaheB3brUoBnAI/0fIQ7Ot/B7KTZzN09l5UHVzI0aigPdn+QNk3amB1io5Kcm8w7W97hl7RfCPIKYkrfKYyKHnVqBbeoX+c9C0gp9RKQprV+/7SySGCZ1rqrbQAYrfXLtp+tBJ61VX1Wa32drfyMelWRMYALV1ZRyb9/2MNHv+0nKsiX6bfGEds60JRYUgtS+Xzn5yxOWWwM7IYN4O4ud9OnZZ9G/2h/rOQYs5NmM2/3PCxWC8PaDuPB2AcJbxJudmh2LfVEKu9ufZfvDnyHn4cf93S9h7ExY/FxN+/J1JHU9SygEK11llIqAvgB6A94aa2P2H7+V6Cv1vpWpVQX4Ev+Nwj8IxCN8WSwB7gaSMcYBB6rtU6q7rqSAC7M3swCJs3bys4jJxjTJ4J/Du9kyh7927O3MztpNqsPr8ZFuTAsahjjuoxzyAHUnJIcZu2YxYLkBVRYK7i+3fWMjx1Pa//WZodmV7KLs/lP4n9YtGcRbi5u3NbpNu7uejcBnva7yWBjVNcJ4DcgCLAAf9Na/6iU+gyIw+jGOQg8cFpCmILRHVQBPKq1/s5WPhSYjjENdJbW+sVzXVcSwPnRWvPpH4d4acUufD3d+NfIbgzq0rCDqVZt5de0X/lkxydsztqMv7s/ozuOZmynsYT4hDRoLGbILs5m5o6ZfJX8FVZtZUT7EYyPHU8rv1Zmh2aq/LJ8Zu2YxZe7vqTCWsGoDqN4IPYBmvs0Nzs0hyQLwZxMVkEpjy9M5OfkbC7v0JzXbo4lxL/hTj4qqyzj233fMidpDgdPHCTUN/TUil1n3JslsyiTGdtnsGjvIjSaUdGjuK/bfXYzu6mhnFxYN2v7LAothQxtO5QJ3SdIF1k9kwTgRFbvzOSJRYkUllXw1NBO3Nm/TYP1rR8vPc685HnM3T2X3NJcOjXrxN1d7+baNtc65Ta8f3a06CgfJ37M1ylfo1Dc1OEm7ut2n8M/DVkqLSzcu5D/bPsPx0qPcXnry/m/Hv9n+roOZyEJwAkUl1fwwvJdfLn+MJ1Cm/DWrXF0aFF3++OcS+qJVD7d+SnfpHxDaWUpA8MGcleXu+jdsnejH9itD+mF6Xyc+DFLUpbgolwY3XE093S9x+G6QCqtlaw4sIL3tr5HemE6vVr0YlLPSfQI6WF2aE5FEoCD256Wz6T5W9ifXcT4y9ry90Ed8HSr/znTB/IP8M6Wd1h9aDVuLm4MbzucOzvfSfum7ev92o4gtSCVjxI/4tt93+Lm4sYtHW/h7q53E+wdbHZoF0Vrzc+pP/P2lrdJOZ5CTLMYJvWcxIBWA+SGwASSABxUpVXz4S/7eHPVHoL9PPn36O5c0r7+G4/8snw+2PYB83fPx9PNkzExYxgbM9bh7mAbyuETh/lP4n9Ytn8ZHi4ejIkZw11d76KZVzOzQztvG49u5K3Nb7EtexttmrRhYtxEBkUOwkXZx8aCzkgSgANKyyvmbwu2seFALsO6hfLijV0J9KnfU48slRbmJc/jw20fUmgpZFT0KCbETSDI2z42j2vsDuYf5MPED1mxfwVebl7c0vEWIptEmh1WrWg0qw+tZm3GWkJ8Qnio+0OMaD+i0Szqc2SSABzMkq3pTP1mB1ar5rkRXRnVM6xeH61PPtK/sekNDp04RP/Q/jzW+zE6NO1Q84vFedt/fD8fbvuQ7w9+jz57gbzdCvAM4L6u93FrzK14uTXcrDNxbpIAHER+iYWnl+xgydYMekYEMv2WHkQE1e9qyeTcZF7b+Brrj64nKiCKx+IfY2DYQOnLbQD5ZfmUVJSYHUatBXoGSsNvh+pyN1BhkvX7j/G3Bds4eqKUv17TgQlXtsPNtf76VXNKcnhnyzss3ruYJp5NmNxnMjd3vFke6RtQgGeArIoVDUYSgB0qr7AyffUePvhlHxHNfPjqwf70jKi/805LK0r5bOdnzNg+g3JrObd3vp0HYh+QhkgIBycJwM7syy7k0Xlb2Z6ez+j41jz9ly74edbP/yatNd8f/J43N73JkaIjXBV+FX+L/5vsaCmEk5AEYCe01nyx/jAvLN+Jl7srH97ek8FdQ+vtetuyt/HqxldJzE4kplkMLwx4gT6hfWp+oRDCYUgCsAO5ReU8vnAbq3dlcWn7YF6/uTstA+pnYO1I4RHe3Pwm3x34jmDvYJ6/5Hmub3e9HLwhzl9+OuQdgMhLzY5EXCBJACazWjUPfraJranHmTqsE/cMiMKlHg5sKbIUMXP7TD7d+SkA42PHc2/Xe2X/dXH+svfA2rcgcT40CYVHtoGLLPpqjCQBmOzz9YfYcDCXV2+KZXR83e+QWGmtZMm+Jbyz5R1ySnIY1nYYk3pMItSv/rqXhINK2wRr/g27l4ObF8TfA/0nSOPfiEkCMFFaXjGvfLebgdHB3Nyr7g8OWX9kPa9tfI3kvGS6N+/OW1e+RWzz2Dq/jnBgWsO+n2DNm3DwN/AKgMv+AX0fAN/GvX+RkARgGq01k7/ejgZeurFbnS6yOph/kDc2vcHPqT/TyrcVr132GtdFXicLuUTtWSth5xKj4T+aCP6hMOhF6DUOPBtmx1lR/yQBmGThpjR+25vDc9d3IbxZ3fTD55fl8+G2D5m3ex6ebp5M6jmJOzrfgaerZ528v3ACllLYNtfo4887AEHt4fp3IXY0uMnvkaORBGCCrBOlTFu2k96RTbmj38XPubdYLSxIXsAH2z6goLyAG9vfyMQeExv9FsOiAZWegIRZsO59KMyEVj3g2s8gZhjIDDGHJQmggWmtmfrNDkorrPxrVOxFzfjRWvNr2q+8nvA6B08cpG9oX/4R/w85dUnUXmEWrPsANs6EsnxoeyWM/BiiLgPpMnR4kgAa2PLtR/hhZyZPDI6hXXO/C36f5NxkXk94nXVH1hHZJJJ3r3qXy1pfJv38onZyD8Dv78CWz6GyHDqPgEsfNe78hdOQBNCAcovKeWZJEt3CArh/YNQFvUdOSQ7vbnmXxSmL8XP348k+TzK642jZsE3UztHtsGY6JH0NLm7QfQxc8ggEy4luzkgSQAN6/tsk8kssfHZv3/Pe1bOssuzUhm1lFWWMjRnLg90flA3bRM20hkO/GzN6UlaBhx/0nwj9HjYWcgmnJQmggfy0O5NvtmbwyFXt6dyqSa1fp7Vm5cGVvLnpTTKKMrgi/Ar+3uvvRAZE1l+wwjFYrbDne6PhT9sAPsFw1T+h973gXX+7y4rGo1YJQCk1CbgfUMDHWuvpp/3sMeA1oLnWOkcZndBvAUOBYuAurfVmW91xwFTbS1/QWs+ps09ix06UWnjq6x1Eh/gx4araP2pvz97OqxtfZWv2Vjo27ciMATPoG9q3HiMVDqHSAtsXwtrpkL0bAiNg6OvQ43Zw9zY7OmFHakwASqmuGI1/H6Ac+F4ptVxrvVcpFQ5cCxw+7SVDgGjbn77AB0BfpVQz4BkgHtDAJqXUUq11Xl1+IHv08ordZBWU8sHtl+DpVvOUuqNFR5m+eTrL9y8nyCuI5y55jhHtRsiGbeLcyotg82fwx7uQnwohXWDkDOhyI7jKw744W21+KzoB67TWxQBKqV+AG4FXgTeBx4Elp9UfAXyqjbMm1ymlApVSocAVwCqtda7tfVYBg4G5dfRZ7NLv+3KYu+Ew910aRY8aDnUpthQzc8dM5iTNQWvN/d3u595u9+Lr7ttA0YpGqTgXNnwM6z+EklyI6A/D3oDoQTKVU5xTbRLADuBFpVQQUILRtZOglLoeSNdab/vT1MMwIPW079NsZdWVO6zi8gqeXLSdNkE+/H1Q9XPzrdrKkhRjw7bskmyGRA3h0Z6P0sqvVQNGKxqd/HT44z3YNBssRdBhMAx4FNr0Nzsy0UjUmAC01ruUUq8Aq4BCYBtQAUwBBlXxkqpuOfQ5ys98sVLjgfEAERERNYVn1974YQ+Hc4uZN74f3h7Vd988vfZpluxbQmzzWN688k26N+/egFGKRuf07Zi1FbrdDAMmQYvOZkcmGpladQxqrWcCMwGUUi8BmcBtwMm7/9bAZqVUH4w7+9P3NW4NZNjKr/hT+c9VXOsj4COA+Pj4sxJEY7H5cB6z1h7gtr4R9GsbVG291YdWs2TfEu7peg+P9nxUFnKJ6lW3HXNTOcJTXJjazgIK0VpnKaUigJFAf631W6f9/CAQb5sFtBSYqJSahzEInK+1PqKUWgm8pJQ62RE+CJhclx/GXpRVVPL4wkRCm3jx5JCYauvlluYybd00OjXrxMQeE6XxF2eT7ZhFPart1IBFtjEACzChhpk7KzDGCVIwpoHeDaC1zlVKTQM22uo9f3JA2NG8+1MKKVmFfHJ3b/y9ql6hq7Vm2h/TKCgvYMagGbKSV5xJtmMWDaC2XUADa/h55Glfa2BCNfVmAbPOI75GZ2fGCT74eR8je4RxZceQauutOLCC1YdX82jPR4luGt2AEQq7dnI75t/fhtz9sh2zqFcyObgOVVRaeXzRNgJ93Pnn8OoH5LKKs3hx/YvENo/lri53NVyAwj5VlBvdO7uXw66lUJRtbMo2+lOIGS7bMYt6IwmgDn302352pJ/g/dt60tTXo8o6Wmue+f0ZLJUWXhzwoizuclalJyBltdHo7/0Byk6Auy+0v9rYqiHqcpnDL+qdJIA6si+7kOmr9zK4S0uGdqt+g63FKYtZk76GJ/s8KfsKvH2DAAAZ3klEQVT5OJuCTEheYTT6B34xtmH2CYYuNxh3+lGXg7uX2VEKJyIJoA5YrZonFibi7e7K8zd0qbZeemE6r2x4hd4tezMmZkwDRihMk5MCu5cZjX7aRkBD0yhjFk/McGjdW7p4hGkkAdSBT/84SMKhPF6/uTsh/lXfwVm1lafXPg3AtAHTcFHntx20aCSsVsjY8r9GPyfZKG/VA66aYjT6zWOke0fYBUkAFyk1t5hXVyZzeYfmjOpZ/c4Wc3fPZcPRDTzb/1nC/Bx6Bwznc/ogbvIKKDhiHLYSeSn0uR86DoGA1mZHKcRZJAFcBK01k7/ejgJeGtmt2oVch04cYvqm6Vwadikjo0c2bJCiflQ3iBt9jXGXH32t7Lkv7J4kgIvwVUIaa1JymDaiC2GBVe+zXmmtZMqaKbi7uvPcJc/Jat/GTAZxhYORBHCBMk+UMm35TvpENeO2vtXvxTJn5xy2ZW/j5YEvE+JT/cIwYadkEFc4MEkAF0BrzdRvdlBeYeWVUbG4uFR9V783by/vbnmXayKuYVjUsAaOUlwQGcQVTkQSwAVYlniEVTszmTwkhqjgqg9rsVgtTFkzBX8Pf6b2mypdP/ZMBnGFk5IEcJ5yi8p5dmkSsa0DuPfSqGrrzUicwa7cXbx5xZsEeVe/HbQwiQziCiEJ4Hw9920SJ0otfHFTX9xcq57Ln3QsiY8SP2JY22Fc0+aaBo5QVEsGcYU4gySA8/DjrkyWbM1g0tXRxLRsUmWdssoypq6ZSjOvZkzu45DHHTQueYcgabEM4gpRBUkAtXSi1MKUxTvo2MKfCVe2r7bee1vfI+V4Cu9f/T4BngENGKE4xVoJe1dBwkzjb7QM4gpRBUkAtfTyil1kFZTynzt64eFWddfP1qytzEmaw6joUQxsfc4jFER9KMiELZ/CpjmQnwp+LeHyx6HH7RDYuM+XFqI+SAKohd9Tcpi7IZXxl7Wle3hglXWKLcVMWTOFlj4t+UfvfzRwhE5Ma2MGT8Is2PUtWCuMvvzrXoSOQ8FVTloTojqSAGpQXF7BE18nEhnkw1+v6VBtvbc2v8XhgsPMHDQTX/eqp4aKOlRy3Dg5K2EW5OwBr0Do+yD0uhuCq++iE0L8jySAGry+cg+puSXMH98Pb4+qBwvXH1nPl7u/5LZOt9EntE8DR+hk0jcZjf72RVBRYgzi3vABdLkR3KvejkMIUTVJAOew6VAen/x+gNv7RdC3bdVz+QvLC3l67dO0adKGST0nNXCETqK8CHYsgo0z4chWY75+91sg/h4I7W52dEI0WpIAqlFWUckTixIJbeLFE4Njqq33esLrHC0+ypzBc/B2kzvQOpW127jb3zYPyvKheScY+rpxQLqXzLAS4mJJAqjGOz+mkJJVyOy7e+PvVfVA4q9pv7Jo7yLu6XoPcSFxDRyhg6ooNw5GT/gEDq0BVw/oPALi74WIfjJ9U4g6JAmgCkkZ+Xzwyz5G9gzjio5V7+CZX5bPs78/S/vA9kyIm9DAETqgvEOwaTZs+QyKsiGwDVzznDGF0zfY7OiEcEiSAP7EUmnl8YWJNPXx4Onhnaut9/KGl8krzePdq9/Fw9WjASN0IKcWbM0y9uNRCjoMNu72210FLnJsphD1qVYJQCk1CbgfUMDHWuvpSqlpwAjACmQBd2mtM5Sx7eVbwFCg2Fa+2fY+44Cptrd9QWs9p04/TR346Nf9JGWc4IPbehLoU3XDvurQKpbvX87DcQ/TOaj6JCGqUZBp3OlvmgP5h8GvBVz2D+h5JwSGmx2dEE6jxgSglOqK0fj3AcqB75VSy4HXtNb/tNV5BHgaeBAYAkTb/vQFPgD6KqWaAc8A8YAGNimllmqt8+r8U12glKxC3vpxL0O6tmRIt9Aq6xwrOca0P6bROagz93W7r4EjbMS0hoNrjO0ZTi3YugwGTYOYYbJgSwgT1OYJoBOwTmtdDKCU+gW4UWv96ml1fDEadTCeCj7VWmtgnVIqUCkVClwBrNJa59reZxUwGJhbJ5/kIlVaNU8sSsTb3ZXnRnSpso7WmmnrplFoKeTFAS/i7iKNVo1KjhuzeBJmGYereAVCnwcg/m4IjjY7OiGcWm0SwA7gRaVUEFCC0bWTAKCUehG4E8gHrrTVDwNST3t9mq2suvIzKKXGA+MBIiIabv+WT/84yKZDebxxc3dC/KveEnj5geX8ePhH/tbrb7RvKqtNzyl9s3G3f3LBVlgvGPE+dB0pC7aEsBM1JgCt9S6l1CvAKqAQ2AZU2H42BZiilJoMTMTo4qlqnp4+R/mfr/cR8BFAfHz8WT+vD6m5xbz6fTKXd2jOyJ5n5SQAMosyeWn9S8Q1j+POznc2RFiNT3kx7Fho3O1nbAF3H2POfvw90EqmyQphb2o1CKy1ngnMBFBKvYRx9366L4HlGAkgDTh9JK81kGErv+JP5T9fQMx1SmvN5K+346LgpZHdqjy6UWvNM388g6XSwguXvoCr7B9/puxko9HfOte2YCsGhrxmrNaVBVtC2K3azgIK0VpnKaUigJFAf6VUtNZ6r63K9cBu29dLgYlKqXkYg8D5WusjSqmVwEtKqZPn7A0CTD8xZUFCKmtScph2Q1fCAqvumli0dxFr09cyuc9k2jRp08AR2qmKctj9LWycZSzYcnE3Fmz1vhci+suCLSEagdquA1hkGwOwABO01nlKqRlKqY4Y00APYcwAAliBMU6QgjEN9G4ArXWuberoRlu9508OCJsl80QpLyzfRZ+oZtzWp+rxhvTCdF7b+Bp9W/bl1phbGzhCO1SaD7+/Y0zhLMoy9tm/+hnocQf4NTc7OiHEeahtF9BZp5torUdVU1cDVS6N1VrPAmadT4D1RWvNlMU7KK+w8sqoWFxczr5jtWor/1z7T5RSPD/geVyUEy9M0hq2fwU/TIXCLGPBVu97od3VsmBLiEbKaVcCf5t4hNW7MnlqaAxRwVXv3z9391w2Ht3I85c8Tyu/Vg0coR3J3AkrHoNDa42jFcfMNWb1CCEaNadMAMcKy3h2aRLdWwdwz4CoKuscyD/Am5veZGDYQG5of0MDR2gnygrg53/Bug/AqwkMn26s1pVBcCEcglMmgGe/3UlBqYVXb+qHm+vZ3ReV1kqmrp2Kp6snz17ybJUzgxya1sb++z9MhYIjRqN/9bPgW/WZCEKIxsnpEsCqnZl8uy2DR6+JpmNL/yrrzE6aTWJ2Iq8MfIUQn6p3A3VY2clGd8+BX43DVkZ/BuG9zY5KCFEPnCoB5JdYmLJ4OzEt/Xn4iqpX8u7J28N7W9/j2jbXMiRqSANHaKKyQvj1VfjjPfDwNQ5eib9HunuEcGBOlQBeWr6LnMIyZoyLx8Pt7K4fS6WFqWum4u/hz9R+U52j60dr2LkEVj4FJ9Ih7na45lmZ0imEE3CaBLBmbw7zE1J54PK2xLYOrLLOR9s/YlfuLqZfOZ1mXs0aOEIT5OyFFf+A/f+FFt3gpk8goq/ZUQkhGohTJICisgqe/DqRqGBf/npNhyrrJB1L4uPEj/lL279wdcTVDRxhAysvgt/egLVvGxuzDXnVOITF1Sl+HYQQNk7xL/61lcmk5ZWw4IH+eLmf3addVlnGlN+mEOQdxBN9njAhwgaiNexeBt9PhvxUiL0Vrn0e/FuYHZkQwgQOnwASDuYy54+D3Nm/DX2iqu7WeW/Le+zL38eH13xIgKeDbl52bB989wSkrIKQznDXCogcYHZUQggTOXQCKLVU8viiRFoFePP44Jgq62zJ2sLspNnc1OEmBoQ5YINoKYHf/g1rp4OrJ1z3MvS5X07gEkI4dgJ4+8e97M8u4tN7+uDnefZHLbYUM3XNVFr5teKx+MdMiLCeJX8H3z0Oxw9Dt5th0Avg39LsqIQQdsJhE8CO9Hz+8+t+burVmss6VD2lcfrm6RwuOMys62bh6171fkCNUu4B+P5J2PO9sTf/uGUQddZ+fkIIJ+eQCcBSaeXxhYk08/Xgn8M6V1ln3ZF1zN09l9s73U7vlg6y0tVSCmvfgjX/BuUK106Dfg9Jd48QokoOmQAyjpdQUGZh2oiuBPic3fgVlBfw9NqniWwSyaSek0yIsB7sXWXM6c87AF1GGt09AVUfbymEEOCgCaBNkC+r/np5lVM+AV7b+BqZxZl8OuRTvNyqPgC+0cg7ZKzi3b0MgjvAnUug7RVmRyWEaAQcMgEA1Tb+v6b9yuKUxdzX7T66N+/ewFHVoYoy+P1t+PUN4/jFa56FfhPAzcPsyIQQjYTDJoCqHC89zjO/P0N002ge6v6Q2eFcuJQfje6e3H3Q6XoY/DIEtDY7KiFEI+NUCeClDS9xvPQ4H1zzAR6ujfBOOT/NWMW7ayk0awe3L4L215gdlRCikXKaBPDDwR/47sB3TIibQEyzqheF2a2Kclj3HvzyqrGdw1X/hEv+D9w8zY5MCNGIOUUCyCnJ4YV1L9AlqAv3drvX7HDOz/6fYfljcGwvxAyH616Cpm3MjkoI4QAcPgForZn2xzSKLEW8eOmLuLs0kjnxJzKM2T1Ji6FpFIz9CjoMMjsqIYQDcfgEsGz/Mn5K/YnH4h+jXWA7s8OpWaXFOIT9l1fAWgFXPAUDJoF7I5+uKoSwO2cfi1UFpdQkpdQOpVSSUupRW9lrSqndSqlEpdRipVTgafUnK6VSlFLJSqnrTisfbCtLUUo9Wfcf50xHi47y8vqX6RHSg9s73V7fl7t4B36DDy+FVf+EyEvh4XVwxRPS+Ash6kWNCUAp1RW4H+gDdAeGK6WigVVAV611LLAHmGyr3xm4FegCDAbeV0q5KqVcgfeAIUBnYIytbr3QWvPs789SoSt4YcALuNrz2baFWbDoPpgzHCzFMGYejJ0PzaLMjkwI4cBq0wXUCVintS4GUEr9AtyotX71tDrrgJtsX48A5mmty4ADSqkUjOQBkKK13m97n3m2ujsv/mOcbeHehazNWMuUvlOIaBJRH5eoGyXHYc5fjA3cLn8CLv2rcUqXEELUs9p0Ae0ALlNKBSmlfIChQPif6twDfGf7OgxIPe1nabay6srrXHphOq9tfI1+of0Y3XF0fVyiblRaYMGdxmEtty+EK5+Sxl8I0WBqfALQWu9SSr2C0eVTCGwDKk7+XCk1xfb9FyeLqnobqk42+s8FSqnxwHiAiIgLu3MP9g7m9k63c3OHm3FRtRrmaHhaw7JH4cAvcMMHEHWZ2REJIZxMrVpHrfVMrXVPrfVlQC6wF0ApNQ4YDtymtT7ZmKdx5hNCayDjHOV/vtZHWut4rXV88+ZV7+NfE09XTx7p+QihfqEX9PoGsebfsOVzo9snbqzZ0QghnFBtZwGF2P6OAEYCc5VSg4EngOtPjg/YLAVuVUp5KqWigGhgA7ARiFZKRSmlPDAGipfW3UdpRLYvhB+fh26j4YrJZkcjhHBStV0HsEgpFQRYgAla6zyl1LuAJ7BKKQXGQPGDWuskpdQCjMHdClv9SgCl1ERgJeAKzNJaJ9Xx57F/h9fBNw9DxCUw4l1jJ08hhDCB+l/Pjf2Jj4/XCQkJZodRd47tgxnXgHdTuG81+DQzOyIhhANSSm3SWsfXVM9OR0gdUHEufHGz8fVtX0njL4QwncNvBWEXKspg3m3Gds7jlkJQI9iSQgjh8CQB1DetYckEOPw7jJoJEf3MjkgIIQDpAqp/P78M278y9vDvdlPN9YUQooFIAqhPW780dvXscQcM/LvZ0QghxBkkAdSXA7/C0kcg6nIY/qZM9xRC2B1JAPUhOxnm324M9o7+FFwbySE0QginIgmgrhVmG9M9XT1h7ALwDqz5NUIIYQKZBVSXLCUwb4yxv//dy+XsXiGEXZMEUFesVlj8AKQlwC2fQVgvsyMSQohzkgRQV358FnYugUEvQqe/mB2NEELUSMYA6kLCJ7D2Leh9H/SfYHY0QghRK5IALlbKalj+d4geBINfkemeQohGQxLAxTi6AxbcBSGd4aZZ4Co9akKIxkMSwIU6cQS+HA2efjB2Pnj6mx2REEKcF7llvRBlhTD3FijNh7u/g4B6OdteCCHqlSSA82WthEX3wdHtMGY+hMaaHZEQQlwQSQDna+VTsOc7GPo6dBhkdjRCCHHBZAzgfKz7ENZ/CP0nQp/7zY5GCCEuiiSA2kr+DlZOhpjhcO3zZkcjhBAXTRJAbWRsgYX3QGgcjPwYXFzNjkgIIS6aJICaHE+FL28Bn2AYMw88fMyOSAgh6oQMAp9L6Qmj8beUwJ1LwL+F2REJIUSdqdUTgFJqklJqh1IqSSn1qK3sZtv3VqVU/J/qT1ZKpSilkpVS151WPthWlqKUerJuP0odq7TAV+MgJ9k41CWkk9kRCSFEnaoxASilugL3A32A7sBwpVQ0sAMYCfz6p/qdgVuBLsBg4H2llKtSyhV4DxgCdAbG2OraH61hxWOw7ycYPh3aXWl2REIIUedq8wTQCVintS7WWlcAvwA3aq13aa2Tq6g/ApintS7TWh8AUjCSRx8gRWu9X2tdDsyz1bU/v78Nm2YbB7n3vMPsaIQQol7UJgHsAC5TSgUppXyAoUD4OeqHAamnfZ9mK6uu3L4kfQOrnoYuI+HKqWZHI4QQ9abGQWCt9S6l1CvAKqAQ2AZUnOMlVe2HrKk62eizXqzUeGA8QERERE3h1a3UjcapXuF94YYPwEUmSQkhHFetWjit9UytdU+t9WVALrD3HNXTOPMJoTWQcY7yP1/rI611vNY6vnnz5rUJr27kHoC5t4J/KNw6F9y9Gu7aQghhgtrOAgqx/R2BMfA79xzVlwK3KqU8lVJRQDSwAdgIRCulopRSHhgDxUsvJvg6U5JnbO1srYDbFoJvkNkRCSFEvavtOoBFSqkgwAJM0FrnKaVuBN4BmgPLlVJbtdbXaa2TlFILgJ0YXUUTtNaVAEqpicBKwBWYpbVOqusPdN4qymH+HZB3EO74BoLbmx2REEI0CKX1Wd3wdiM+Pl4nJCTU3wW0hm8egm1zjS0eYkfX37WEEKKBKKU2aa3ja6rn3KOcv75mNP5XPCWNvxDC6ThvAkhcAP99EbqPgcsfNzsaIYRocM6ZAA6uhSUTIHIg/OVtUFXNXBVCCMfmfAkgJwXm3wZNI+GWz8DNw+yIhBDCFM6VAIqOwRc3gXKFsQvAu6nZEQkhhGmcZztoSynMGwMFR2DcMmgWZXZEQghhKudIAFarMd0zdT3cPAfCe5sdkRBCmM45uoD++wIkfQ3XPAddbjA7GiGEsAuOnwA2fwa/vQG97oIBk8yORggh7IZjJ4B9/4Vlj0K7q2Do6zLdUwghTuO4CSBrFyy4E4I7Gv3+ru5mRySEEHbFMRNAQSZ8MRrcvWHsfPBqYnZEQghhdxwzAbh5QIvORuMfeK7Dy4QQwnk55jRQ76ZG4y+EEKJajvkEIIQQokaSAIQQwklJAhBCCCclCUAIIZyUJAAhhHBSkgCEEMJJSQIQQggnJQlACCGclNJamx1DtZRS2cChi3iLYCCnjsKpb40pVmhc8TamWKFxxduYYoXGFe/FxNpGa928pkp2nQAullIqQWsdb3YctdGYYoXGFW9jihUaV7yNKVZoXPE2RKzSBSSEEE5KEoAQQjgpR08AH5kdwHloTLFC44q3McUKjSvexhQrNK546z1Whx4DEEIIUT1HfwIQQghRDYdMAEqpwUqpZKVUilLqSbPjORel1CylVJZSaofZsdREKRWulPqvUmqXUipJKTXJ7JjORSnlpZTaoJTaZov3ObNjqolSylUptUUptczsWGqilDqolNqulNqqlEowO55zUUoFKqUWKqV2235/+5sdU3WUUh1t/01P/jmhlHq0Xq7laF1ASilXYA9wLZAGbATGaK13mhpYNZRSlwGFwKda665mx3MuSqlQIFRrvVkp5Q9sAm6w4/+2CvDVWhcqpdyBNcAkrfU6k0OrllLqb0A80ERrPdzseM5FKXUQiNda2/28eqXUHOA3rfUMpZQH4KO1Pm52XDWxtWfpQF+t9cWsiaqSIz4B9AFStNb7tdblwDxghMkxVUtr/SuQa3YctaG1PqK13mz7ugDYBYSZG1X1tKHQ9q277Y/d3vEopVoDw4AZZsfiSJRSTYDLgJkAWuvyxtD421wN7KuPxh8cMwGEAamnfZ+GHTdSjZVSKhLoAaw3N5Jzs3WpbAWygFVaa3uOdzrwOGA1O5Ba0sAPSqlNSqnxZgdzDm2BbOATW/faDKWUr9lB1dKtwNz6enNHTACqijK7vetrjJRSfsAi4FGt9Qmz4zkXrXWl1joOaA30UUrZZTebUmo4kKW13mR2LOdhgNa6JzAEmGDrzrRHbkBP4AOtdQ+gCLDrsUEAW1fV9cBX9XUNR0wAaUD4ad+3BjJMisXh2PrSFwFfaK2/Njue2rI98v8MDDY5lOoMAK639avPA65SSn1ubkjnprXOsP2dBSzG6H61R2lA2mlPfwsxEoK9GwJs1lpn1tcFHDEBbASilVJRtgx6K7DU5Jgcgm1QdSawS2v9b7PjqYlSqrlSKtD2tTdwDbDb3KiqprWerLVurbWOxPid/UlrfbvJYVVLKeVrmwiArTtlEGCXM9m01keBVKVUR1vR1YBdTlz4kzHUY/cPGI9GDkVrXaGUmgisBFyBWVrrJJPDqpZSai5wBRCslEoDntFazzQ3qmoNAO4Attv61QGe0lqvMDGmcwkF5thmUrgAC7TWdj+9spFoASw27glwA77UWn9vbkjn9H/AF7abwv3A3SbHc05KKR+MmYwP1Ot1HG0aqBBCiNpxxC4gIYQQtSAJQAghnJQkACGEcFKSAIQQwklJAhBCCCclCUAIIZyUJAAhhHBSkgCEEMJJ/T+RHBusXeweUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xi,yi)\n",
    "plt.plot(xii,yii)\n",
    "plt.plot(xiii,yiii) # greeen and corresponds to 1ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Green one (1iii) decreases in accuracy after the 3rd epoch and never gets to higher accuarcy again so its been overtrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) most often = 0\n",
    "ii) least often = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(r\"C:\\Users\\seane\\Downloads\\regression.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamatrix = np.array([data])\n",
    "# just putting the data into a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =datamatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1001, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =A[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  6.66254416e+00],\n",
       "       [ 5.00000000e-03,  7.12572823e+00],\n",
       "       [ 1.00000000e-02,  7.68314910e+00],\n",
       "       ...,\n",
       "       [ 4.99000000e+00, -1.91212156e+01],\n",
       "       [ 4.99500000e+00, -1.75719493e+01],\n",
       "       [ 5.00000000e+00, -1.81594668e+01]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = A[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.66254416,   7.12572823,   7.6831491 , ..., -19.12121562,\n",
       "       -17.57194928, -18.15946684])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.ones(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.005, 0.01 , ..., 4.99 , 4.995, 5.   ])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ai = A[:,0]\n",
    "Ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anew = np.column_stack((x0,Ai)) # as in assignment 3, building the matrix A with first column as 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [1.   , 0.005],\n",
       "       [1.   , 0.01 ],\n",
       "       ...,\n",
       "       [1.   , 4.99 ],\n",
       "       [1.   , 4.995],\n",
       "       [1.   , 5.   ]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Anew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 2)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Anew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q,R = np.linalg.qr(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat = np.linalg.inv(R)@np.transpose(Q)@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.22044605e-16,  1.00000000e+00])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = -2.22044605e-16 + 1.00000000e+00*x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.22044605e-16,  5.00000000e-03,  1.00000000e-02, ...,\n",
       "        4.99000000e+00,  4.99500000e+00,  5.00000000e+00])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(Ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373.63970018961993"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(f(Ai)-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-80-3d74dbe3bc2c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-80-3d74dbe3bc2c>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    f(i) = Ai[i]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,1000):\n",
    "    f(i) = Ai[i]\n",
    "    e[i] = np.linalg.norm(f(i)-b(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-f20d9473a303>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(x[i],e[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthdistance(x,y):\n",
    "    np.mod(1.00000000e+00*x + y -2.22044605e-16)/np.sqrt(((1.00000000e+00)**2)+1)\n",
    "    return orthdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-87-2d23f9283ff3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-87-2d23f9283ff3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    g(x) = np.min(x,y,orthdistance)\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "g(x) = np.min(x,y,orthdistance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-88-23a3651dcb2e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-88-23a3651dcb2e>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    g(i) = Ai[i]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,1000):\n",
    "    g(i) = Ai[i]\n",
    "    e[i] = np.linalg.norm(g(i)-b(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-f20d9473a303>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(x[i],e[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-c8b336c4294c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(x[i],f(x[i]))\n",
    "plt.plot(x[i],g(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
